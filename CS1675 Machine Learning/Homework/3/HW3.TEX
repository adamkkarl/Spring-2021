\documentclass[a4paper]{article}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx} 

%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

%% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}

\title{Homework 2}
\author{Adam Karl}

\begin{document}
\maketitle

\section{Problem 1}

\noindent
a.

\begin{center}
    \includegraphics[scale=1]{1a.png}
%    \caption{Subsample size = 25}
\end{center}

\noindent
b. 

\noindent
mean vector: 

$$\left( \begin{matrix} 3.6377 & 7.8506 \end{matrix} \right) $$

\noindent
covariance matrix:


$$\left( \begin{matrix} 3.6414 & 1.0779 \\ 1.0779 & 3.7831 \end{matrix} \right) $$

\begin{center}
    \includegraphics[scale=1]{1b.png}
%    \caption{Subsample size = 25}
\end{center}

\noindent
c. 
\begin{itemize}
    \item var 1
    \begin{itemize}
        \item mean = 3.6377
        \item variance = 3.6414
    \end{itemize}
    \item var 2
    \begin{itemize}
        \item mean = 7.8506
        \item variance = 3.7831
    \end{itemize}
\end{itemize}


\begin{center}
    \includegraphics[scale=1]{1c-1.png}
    \caption{variable 1}
\end{center}


\begin{center}
    \includegraphics[scale=1]{1c-2.png}
    \caption{variable 2}
\end{center}

\noindent
d. 

\noindent
The multivariate Gaussian model is certainly better than two separate univariate Gaussian models because it includes correlation data. For this specific example, the correlation is extremely loose (value of 1.0779 from the covariance matrix) so it's not quite as important, but for other data sets it may have a much more noticeable correlation.

\noindent
For instance, if var1 was father heights and var2 was children heights, then if you only looked at each variable individually then you would only see two normal-like distributions, and completely miss that taller fathers correspond to taller children.


\section{Problem 2}

\noindent
a.

\begin{center}
    \includegraphics[scale=1]{2a-1.png}
    \caption{lambda = 2}
\end{center}

\begin{center}
    \includegraphics[scale=1]{2a-2.png}
    \caption{lambda = 6}
\end{center}

\noindent
b. 
$\lambda_{ML}$ = mean = 5.2400

\noindent
Since variance = mean/n, we can calculate the standard deviation = 0.4578 and plot:

\begin{center}
    \includegraphics[scale=1]{2b.png}
    \caption{prob. function for ML parameter}
\end{center}

c. 

\begin{center}
    \includegraphics[scale=1]{2c-1.png}
    \caption{beta dist with a=1, b=2}
\end{center}

\begin{center}
    \includegraphics[scale=1]{2c-2.png}
    \caption{beta dist with a=3, b=5}
\end{center}

\noindent
d.

\noindent
a=1, b=2:

$$p(\lambda|D)\sim Gamma(\lambda |a+\sum_{i=1}^{n}x_i, \frac{b}{nb+1})$$

$$p(\lambda|D)\sim Gamma(1+\sum_{i=1}^{25}x_i, \frac{2}{25(2)+1})$$

$$p(\lambda|D)\sim Gamma(132, \frac{2}{51})$$

\begin{center}
    \includegraphics[scale=1]{2d-1.png}
    \caption{posterior 1}
\end{center}




a=3, b=5:

$$p(\lambda|D)\sim Gamma(\lambda |a+\sum_{i=1}^{n}x_i, \frac{b}{nb+1})$$

$$p(\lambda|D)\sim Gamma(3+\sum_{i=1}^{25}x_i, \frac{2}{25(5)+1})$$

$$p(\lambda|D)\sim Gamma(135, \frac{1}{63})$$

\begin{center}
    \includegraphics[scale=1]{2d-2.png}
    \caption{posterior 2}
\end{center}

\section{Problem 3}

Part 1
\begin{center}
    \includegraphics[scale=1]{3-1.png}
    \caption{training data}
\end{center}

\noindent
Part 2

\noindent
a.

\noindent
with h=0.025
\begin{itemize}
    \item p(0.1362) = 1.6
    \item p(0.2928) = 0
    \item p(0.4491) = 1
    \item p(0.6517) = 2.1333
    \item p(0.7936) = 1.6
    \item p(0.6664) = 2.1333
\end{itemize}

\begin{center}
    \includegraphics[scale=1]{3a.png}
    \caption{h=0.025}
\end{center}

\noindent
b. 

\noindent
with h=0.1:
\begin{itemize}
    \item p(0.1362) = 1.4667
    \item p(0.2928) = 0.2667
    \item p(0.4491) = 0.9333
    \item p(0.6517) = 1.6
    \item p(0.7936) = 1.3333
    \item p(0.6664) = 1.7333
\end{itemize}

\begin{center}
    \includegraphics[scale=1]{3b.png}
    \caption{h=0.1}
\end{center}

\noindent
Increasing the h from 0.025 to 0.1 seems to smooth out the graph a lot, while decreasing the amplitude of the probability function. In the h=0.025 graph it's more obvious that individual points correspond to spikes in the graph. The peaks are still generally in the same places, but heavily smoothed out.

\noindent
Part 3

\noindent
a.

\noindent
with k=3:
\begin{itemize}
    \item p(0.1362) = 1.7814
    \item p(0.2928) = 0.3448
    \item p(0.4491) = 1.0797
    \item p(0.6517) = 3.0180
    \item p(0.7936) = 3.0398
    \item p(0.6664) = 2.8816
\end{itemize}

\begin{center}
    \includegraphics[scale=1]{3-3a.png}
    \caption{k=3}
\end{center}

\noindent
b.

\noindent
with k=5
\begin{itemize}
    \item p(0.1362) = 1.8278
    \item p(0.2928) = 0.5311
    \item p(0.4491) = 0.8786
    \item p(0.6517) = 2.3900
    \item p(0.7936) = 0.9994
    \item p(0.6664) = 2.5931
\end{itemize}

\begin{center}
    \includegraphics[scale=1]{3-3b.png}
    \caption{k=5}
\end{center}

\noindent
c. 

\noindent
Increasing the k from 3 to 5 seems to slightly smooth out the graph, while decreasing the amplitude of the probability function. The peaks are still generally in the same places, but are significantly decreased around x=0.5, supposedly because there were enough nearby points to satisfy k=3 easily, but the kNN function had to search much farther for a 5th point.

\end{document}
